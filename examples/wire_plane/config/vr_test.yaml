# Test config file for Blip
dataset:
  # If this is the first time processing the simulation output
  process_simulation: False
  simulation_files:   [
    "data/protodune_mc_0.root",
    "data/protodune_mc_1.root",
    "data/protodune_mc_2.root",
    "data/protodune_mc_3.root",
    "data/protodune_mc_4.root",
    "data/protodune_mc_5.root",
    "data/protodune_mc_6.root",
    "data/protodune_mc_7.root",
    "data/protodune_mc_8.root",
    "data/protodune_mc_9.root",
    "data/protodune_mc_10.root",
  ]

  # Otherwise, we want to just load the resulting data
  dataset_type:   "wire_plane"
  dataset_files:  [
    "data/blip_simulation_0/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_1/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_2/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_3/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_4/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_5/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_6/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_7/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_8/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_9/point_cloud_view0_tpc0.npz",
    "data/blip_simulation_10/point_cloud_view0_tpc0.npz",
  ]
  classes:        ["source", "shape", "particle"]

loader:
  batch_size:       1
  test_split:       0.1
  test_seed:        100
  validation_split: 0.2
  validation_seed:  100
  num_workers:      4

training:
  epochs:       25
  checkpoint:   10
  progress_bar: 'all'   # train, validation, test, all
  rewrite_bar:  False   # wether to leave bars after each epoch
  save_predictions: True  # wether to save network outputs in original file
  no_timing:  False     # wether to keep timing/memory info in callback
  gpu:        True
  gpu_device: 0
  seed:       42

model:
  model_type:   "VietorisRipsNet"
  set_abstraction_layers:
    coarse_graining_eps:    [5, 10]
    eps_embedding_vals:     [[5, 6, 7], [10, 11, 12]]
    pointnet_embedding_type:        ["dynamic_edge_conv", "dynamic_edge_conv"]
    pointnet_embedding_mlp_layers:  [[16,16],[16,16]]
    pointnet_number_of_neighbors:   [20, 20]
    pointnet_aggregation:           ["max", "max"]
    pointnet_input_dimension:       [3, 51]
  feature_propagation_layers:
    coarse_graining_eps:    [10, 5]
    embedding_mlp_layers:   [[102, 256], [262, 512]]
  segmentation_layer:
    # number of inputs is original coordinates + embeddings
    num_inputs:   515
    mlp_layers:   [1024, 512, 128]
    classifications:  ["source", "shape", "particle"]
    number_of_classes: [8, 7, 32]
  classification_layers:

criterion:
  multiclass_nll_loss:
    alpha:  1.0
    
metrics:
  confusion_matrix:
    inputs: ["source", "shape", "particle"]
    number_of_classes: [8, 7, 32]

callbacks:
  loss:
  confusion_matrix:
    sig_acceptance: [0.1, 0.5, 0.9]

optimizer:
  optimizer_type: "Adam"
  learning_rate:  0.01
  betas:          [0.9, 0.999]
  epsilon:        1e-08
  weight_decay:   0.001
  momentum:       0.9